---
output: github_document
---

##### Devon Park (dap2189)
##### Assignment 3 - Due 13NOV25

```{r, message=FALSE}
library(readxl)
library(dplyr)
library(ggplot2)
library(tibble)
```

### Question 1

The data below show plasma inorganic phosphate measurements obtained from 13 controls (‘group’ = 0) and 20 obese patients (‘group’ =1) taken initially (‘initial’) and 3 hours after an oral glucose challenge (‘final’). The aim is to find if there is a difference in the final phosphate measurements between the two groups after adjusting for any initial difference.

```{r, echo=FALSE}
# Import the data

Q1 = read_excel("data/Asst_3_Q1.xlsx")
knitr::kable(head(Q1), caption = "First few rows of Q1 dataset")
```

#### (a) Write down a simple ANCOVA model for data shown, using the control group as a reference.

```{r, echo=FALSE}
m1 <- lm(final ~ group + initial, data = Q1)
summary(m1)
```

Parallel slopes Model: 

$final = \beta_0 + \beta_1 * group + \beta_2 * initial + \epsilon$

<mark> Model with coefficients: </mark> 
$final = 0.889 - 0.234x_{group} + 0.601x_{initial}$

*Note: group = 0 for the control (reference group) and group = 1 for obese patients.*


#### (b) Test for any difference in the outcome between the two groups.

```{r, include = FALSE, eval = FALSE}
# If i wanted to make group a factor variable (rather than a binary 0/1), but this is not necessary

Q1 = Q1 |> 
  mutate(group = factor(group, 
                        levels = c(0, 1), 
                        labels = c("Control", "Obese")))

```


```{r, echo=FALSE, results = 'hide'}
summary(m1)           
anova(m1)               # shows F-test for group and Initial
```

Looking at our regression model, we see the coefficient for variable group is $-0.234$ with a p-value of $0.286$. This means that the adjusted difference in the final phosphate readings for obese participants compared to control participants is $-0.234$. However, the p-value is greater than 0.05 which means this difference is not statistically significant at the 5% significance level. 

#### (c) Does the initial phosphate value contribute significantly to the final phosphate value?

Looking at our regression model, we see the coefficient for variable initial is $0.601$ with a p-value of $0.004$. This means that for every one unit increase in initial phosphate value, the final phosphate value increases by roughly 0.6 units, after adjusting for group. That the p-value is less than 0.05 suggests the association between initial and final phosphate scores is statistically significant. 

#### (d) Repeat the ANCOVA without assuming parallel slopes for the two groups
The interaction term tests whether the relation between initial and final phosphate values differ by group. If slopes are parallel $\beta_3=0$. 

```{r, echo=FALSE}
#add an interaction term between group and initial 

m2 <- lm(final ~ group + initial + group:initial, data = Q1)

summary(m2)
anova(m1, m2)
```

Non-parallel slopes Model: 

$final = \beta_0 + \beta_1 * group + \beta_2 * initial + \beta_3 * (group*initial) + \epsilon$

<mark> Model with coefficients: </mark> 
$final = 0.538 + 0.190x_{group} + 0.686x_{initial} - 0.102x_{group*initial}$

*Note: group = 0 for the control patients (reference group) and group = 1 for obese patients.*



The interaction term in model2 is $\beta_3=-0.102$ with a p-value of $0.810$. That the p-value is >0.05 suggests that initial and final phosphate values are not statistically significantly different depending on group. In other words, the association between initial and final phosphate scores is roughly similar across both groups. 


Additionally, I ran `anova(m1, m2)` to compare m1 (parallel slopes model) with m2 (non-parallel slopes model). From this test, I get an F test statistic of $0.059$ with a p-value of $0.810$ suggesting that adding the interaction term does not significantly improve the model. In other words, we fail to reject the null hypothesis $H_0: \beta_3 =0$. 


## Question 2

The US Navy attempts to develop equations for estimation of manpower needs for manning installations such as Bachelor Officers Quarters (BOQ). Regression equations are developed from data taken by measurement teams. The data in the attached excel file were collected from 25 BOQ sites.

###### Variables of Dataset:
$X_1$ = average daily occupancy

$X_2$ = monthly average number of check-ins 

$X_3$ = weekly hours of service desk operation

$X_4$ = square feet of common use area

$X_5$ = Number of building wings

$X_6$ = operational berthing capacity

$X_7$ = number of rooms

$Y$ = monthly man-hours

#### (a) *Fit* the regression model

```{r, echo=FALSE}
#Import Data set

Q2 = read_excel("data/Asst3_Q2.xlsx")
knitr::kable(head(Q2), caption = "First few rows of Q2 dataset")
```

```{r, echo=FALSE}
#Run model
m3 <- lm(y ~ x1 + x2 + x3 + x4+ x5 + x6 + x7, data = Q2)
summary(m3)
```

From our regression model I get the following result:
Regression Model Form: $Y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \beta_4x_4 + \beta_5x_5 + \beta_6x_6 + \beta_7x_7 + \epsilon$

<mark> Regresssion Model:</mark> $Y = 135.038 - 1.284x_1 + 1.804x_2 + 0.669x_3 - 21.436x_4 + 5.622x_5 - 14.490x_6 + 29.335x_7$

#### (b) Perform a residual plot and make any necessary transformations.

```{r, echo=FALSE}
#Include columns for residuals and and fitted values.

Q2 = 
  Q2 |> 
    mutate(
    residuals = resid(m3),
    fitted = fitted(m3)
  )
```

```{r, echo=FALSE}
#Create residual plot


ggplot(Q2, aes(x = fitted, y = residuals)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "steelblue") +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal()
```


Based on the residual plot, we see a funneling effect suggesting heteroscedasticity (residuals spreading as our fitted values increase). This suggests that we should transform our data using a natural log. 

```{r, echo=FALSE}
#log transform the data 

Q2 =
  Q2 |>
    mutate(log_y = log(y)
           )
```



#### (c) Refit a linear regression based on your transformation.

Refit the model with the transformation:
```{r, echo=FALSE}
m3_log <- lm(log_y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7, data = Q2)
summary(m3_log)
```


Check residuals again:
- After the log transformation, we see that our residuals form a cloud like shape suggesting a more even spread. 
```{r, echo=FALSE}
Q2 = 
  Q2 |> 
    mutate(
      residuals_log = resid(m3_log),
      fitted_log = fitted(m3_log)
          )

ggplot(Q2, aes(x = fitted_log, y = residuals_log)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "steelblue", linetype = "dashed") +
  labs(
    title = "Residuals vs Fitted (After Log Transformation)",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal()
```

Now that we have log transformed our data, a new interpretation of our results would be as follows: 
- A one-unit increase in $x_i$ is associated with an estimated $100 * β_i$ % change in monthly man-hours, holding the other variables constant.


#### (d) Compute the hat diagonals, Standardized residuals, Cook’s distance, and Studentized residuals for the model in (c)

```{r, echo=FALSE}

#fitted already calculated

Q2_diagnostics = 
    Q2 |> 
    mutate(
      hat = hatvalues(m3_log),
      std_resid = rstandard(m3_log),
      stud_resid = rstudent(m3_log),
      cooks = cooks.distance(m3_log)
      )

knitr::kable(head(Q2_diagnostics))
```



#### (e) Identify any influential points and discuss the nature of the influence.

Points that are high leverage look at how far an observation's x values are from the mean of all x's. 

We can use cooks distance to look at how much the fitted model changes when a certain observation is removed. WE consider a point influential if D (cook's distance) is greater than 1.

```{r, echo=FALSE}
# For both high leverage and influential points

n <- nrow(Q2_diagnostics)
p <- length(coef(m3_log))  # number of parameters in model (including intercept)

Q2_diagnostics_influence_leverage = 
  Q2_diagnostics |>
    mutate(
      high_leverage = hat > (2 * p / n),
      influential = cooks > (4 / n)
      )

Q2_diagnostics_influence_leverage |> filter(high_leverage | influential) |> knitr::kable()
```


```{r, echo=FALSE}
#Using cook's distance only

Q2_diagnostics = 
  Q2_diagnostics |>
    mutate(
      influential = cooks > 1
      )

```


By filtering our table, we can see how there is only 1 influential point:
```{r, echo=FALSE}
Q2_diagnostics |> 
  filter(influential) |> 
  knitr::kable()
```

We can also see our influential point more clearly graphically:
```{r, echo=FALSE}

#Visualise influential point
ggplot(Q2_diagnostics, aes(x = x1, y = log_y)) +
  geom_point(aes(color = influential), size = 2) +
  scale_color_manual(values = c("FALSE" = "grey50", "TRUE" = "red")) +
  labs(
    title = "log(Y) vs X1 with Influential Point Highlighted",
    x = "Average Daily Occupancy (X1)",
    y = "log(Monthly Man-Hours)",
    color = "Influential?"
  ) +
  theme_minimal()
```

I would remove the point from site 23 because it is influential as seen in the plot below.
```{r, echo=FALSE}

Q2_revised = 
  Q2_diagnostics |>
  filter(influential == FALSE)

#Visualise without influential point
ggplot(Q2_revised, aes(x = x1, y = log_y)) +
  geom_point(aes(color = influential), size = 2) +
  scale_color_manual(values = c("FALSE" = "grey50", "TRUE" = "red")) +
  labs(
    title = "log(Y) vs X1 with Influential Point Highlighted",
    x = "Average Daily Occupancy (X1)",
    y = "log(Monthly Man-Hours)",
    color = "Influential?"
  ) +
  theme_minimal()

```


#### (f) Identify any outliers and take any remedial action necessary.

We look a the studentized residuals to find outliers. If the absolute value of this value is greater than 2, we classify it as an outlier. 
```{r, echo=FALSE}
#Look at stud_resid where absolute value is greater than 2 to see if it is an outlier

Q2_diagnostics |> 
  filter(abs(stud_resid) > 2) |> 
  knitr::kable()

```

We can see outliers graphically below:
```{r, echo=FALSE}
#Visualize the outlier 

ggplot(Q2_diagnostics, aes(x = fitted, y = stud_resid)) +
  geom_point(aes(color = abs(stud_resid) > 2), size = 2) +
  geom_hline(yintercept = c(-2, 2), color = "steelblue", linetype = "dashed") +
  labs(
    title = "Studentized Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Studentized Residuals",
    color = "Outlier (|r| > 2)"
  ) +
  scale_color_manual(values = c("FALSE" = "grey60", "TRUE" = "red")) +
  theme_minimal()
```

Point for site 7 is found as an outlier because the absolute value of the studentized residuals is greater than 2. This point does not meet the criteria for being influential. So, I expect to keep this point in my dataset. 




